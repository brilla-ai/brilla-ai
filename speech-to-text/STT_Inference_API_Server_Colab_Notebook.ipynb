{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nsmq-ai/nsmqai/blob/kojomensahonums-add-stt-inference-notebook/STT_Inference_API_Server_Colab_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Phsd-uQ9skuK"
      },
      "outputs": [],
      "source": [
        "# Import and install the required libraries\n",
        "\n",
        "%%capture\n",
        "!pip install git+https://github.com/openai/whisper.git\n",
        "!pip install jiwer\n",
        "!pip install tabulate\n",
        "!pip install pydub\n",
        "import torch\n",
        "import numpy as np\n",
        "import whisper\n",
        "import jiwer\n",
        "import time\n",
        "import pandas as pd\n",
        "from tabulate import tabulate\n",
        "from pydub import AudioSegment\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Yzf7vnunmRfV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Gme-keulsuJ3"
      },
      "outputs": [],
      "source": [
        "# Load whisper model\n",
        "\n",
        "%%capture\n",
        "whisper.load_model(\"medium.en\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "CEJ1_QYHsyW_"
      },
      "outputs": [],
      "source": [
        "torch.cuda.is_available()\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "model = whisper.load_model(\"medium.en\", device = DEVICE) # Select whisper model size (tiny, base, small, medium, large)\n",
        "# print(\n",
        "#       f\"Model is {'multilingual ' if model.is_multilingual else 'English only'}\"\n",
        "#       f\"and has {sum(np.prod(p.shape) for p in model.parameters()):,} parameters.\"\n",
        "\n",
        "def transcribe(path_to_audio):\n",
        "\n",
        "  # Load audio\n",
        "  audio = whisper.load_audio(path_to_audio)\n",
        "\n",
        "  # Measure start time\n",
        "  #start = time.time()\n",
        "\n",
        "  # Transcribe audio\n",
        "  result = model.transcribe(audio)\n",
        "\n",
        "  # Measure duration of transcription time\n",
        "  #transcription_time = time.time()-start\n",
        "  #print(f\"The transcription time is {transcription_time} seconds\")\n",
        "\n",
        "  # Print transcript\n",
        "  return result[\"text\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "v2xrHNXtLhSY"
      },
      "outputs": [],
      "source": [
        "# Install required libraries for web api\n",
        "!pip -q install fastapi\n",
        "!pip -q install pyngrok\n",
        "!pip -q install uvicorn\n",
        "!pip -q install nest_asyncio\n",
        "!pip -q install python-multipart"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4MIeAXHiLjLm"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import uvicorn\n",
        "from fastapi import FastAPI\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "from pyngrok import ngrok\n",
        "from pydantic import BaseModel\n",
        "import nest_asyncio\n",
        "\n",
        "import shutil\n",
        "\n",
        "nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "DGpm5GvgL4Qr"
      },
      "outputs": [],
      "source": [
        "# Import models for serialisation/ deserialisation\n",
        "from pydantic import BaseModel\n",
        "import base64\n",
        "import io\n",
        "import wave\n",
        "\n",
        "\n",
        "class AudioBytes(BaseModel):\n",
        "  data: bytes\n",
        "  filename: str\n",
        "\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=['*'],\n",
        "    allow_credentials=True,\n",
        "    allow_methods=['*'],\n",
        "    allow_headers=['*'],\n",
        ")\n",
        "\n",
        "@app.get(\"/get-transcript\")\n",
        "async def get_transcript(audio: AudioBytes):\n",
        "  decoded_data = base64.b64decode(audio.data)\n",
        "\n",
        "  # Write bytes data to a .wav file\n",
        "  with io.BytesIO(decoded_data) as audio_file:\n",
        "    with wave.open(audio_file, \"wb\") as wav:\n",
        "      wav.setnchannels(1)\n",
        "      wav.setsampwidth(2)\n",
        "      wav.setframerate(16000)\n",
        "\n",
        "      # Write .wav files\n",
        "      wav.writeframes(decoded_data)\n",
        "\n",
        "  # Save the audio file with the custom name\n",
        "    audio_filename = audio.filename\n",
        "    with open(audio_filename, \"wb\") as file:\n",
        "        file.write(decoded_data)\n",
        "\n",
        "   # Get transcript and delete temporary audio file\n",
        "  print(\"audio_filename \",audio_filename)\n",
        "  transcript = transcribe(audio_filename)\n",
        "  os.remove(audio_filename)\n",
        "\n",
        "  return {\"transcript\": transcript}\n",
        "\n",
        "@app.get(\"/\")\n",
        "async def home():\n",
        "  return {\"msg\":\"Hello from STT.\"}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Rrh5RexfIrg7"
      },
      "outputs": [],
      "source": [
        "# Attach personal token\n",
        "!ngrok config add-authtoken <place_your_ngrok_auth_token_here>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "IMR03ze9IKls"
      },
      "outputs": [],
      "source": [
        "# Link to model in API ??\n",
        "ngrok_tunnel = ngrok.connect(8000)\n",
        "print(\"Public URL:\", ngrok_tunnel.public_url)\n",
        "uvicorn.run(app, port=8000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8cyX1L8MS-vX"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
