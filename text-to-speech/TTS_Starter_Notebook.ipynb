{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### AfricAIED Brilla Hackathon 2024\n",
        "This notebook is to help you get started on how to setup the various trained speech synthesis models for your project. There are two models in the *AI Voice models* folder you have been given access to. One of the models is that of the quizmistress and the other is that of a student. The set up of the two models follow the same procedure."
      ],
      "metadata": {
        "id": "eyu93xTSnKEJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uXi8dSW4nC8E"
      },
      "outputs": [],
      "source": [
        "# Make sure the following requirements are installed. Ignore any warnings that show up during installation\n",
        "%%bash\n",
        "pip install TTS onnx onnxruntime\n",
        "sudo apt-get install espeak-ng"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import the required libraries\n",
        "from TTS.tts.configs.vits_config import VitsConfig\n",
        "from TTS.tts.models.vits import Vits\n",
        "from TTS.utils.audio.numpy_transforms import save_wav\n",
        "import numpy as np\n",
        "import IPython"
      ],
      "metadata": {
        "id": "cyoVNf8fsE6A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the student model"
      ],
      "metadata": {
        "id": "ZlOj9rbMqsEU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load the model's config file\n",
        "student_config=VitsConfig()\n",
        "student_config.load_json('/path/to/student/config')\n",
        "\n",
        "# load the model\n",
        "student_model=Vits.init_from_config(student_config)\n",
        "student_model.load_onnx('/path/to/student/model')"
      ],
      "metadata": {
        "id": "VCo860m0qSig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text=  #text to synthesize\n",
        "out_path= # path to save synthesized speech\n",
        "\n",
        "# generate the speech\n",
        "text_inputs = np.asarray(\n",
        "    student_model.tokenizer.text_to_ids(text, language=\"en\"),\n",
        "    dtype=np.int64,\n",
        ")[None, :]\n",
        "audio = student_model.inference_onnx(text_inputs,speaker_id=0)\n",
        "\n",
        "# save the synthesized speech\n",
        "save_wav(wav=audio[0], path=out_path,sample_rate=22050)"
      ],
      "metadata": {
        "id": "EuPY7dONqrMU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the audio\n",
        "IPython.display.Audio(out_path)"
      ],
      "metadata": {
        "id": "1fd8U0BmuFz3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the quizmistress model"
      ],
      "metadata": {
        "id": "I_eHcTzTs4qs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load the model's config file\n",
        "qm_config=VitsConfig()\n",
        "qm_config.load_json('/path/to/quizmistress/config')\n",
        "\n",
        "# load the model\n",
        "qm_model=Vits.init_from_config(qm_config)\n",
        "qm_model.load_onnx('/path/to/quizmistres/model')"
      ],
      "metadata": {
        "collapsed": true,
        "id": "_KcdWwJhsTWE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text= #text to synthesize\n",
        "out_path=  # path to save synthesized speech\n",
        "\n",
        "# generate the speech\n",
        "text_inputs = np.asarray(\n",
        "    qm_model.tokenizer.text_to_ids(text, language=\"en\"),\n",
        "    dtype=np.int64,\n",
        ")[None, :]\n",
        "audio = qm_model.inference_onnx(text_inputs,speaker_id=0)\n",
        "\n",
        "# save the synthesized speech\n",
        "save_wav(wav=audio[0], path=out_path,sample_rate=22050)"
      ],
      "metadata": {
        "id": "Jtsis8_zsUQR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load the audio\n",
        "IPython.display.Audio(out_path)"
      ],
      "metadata": {
        "id": "i3guTffAwW0f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}